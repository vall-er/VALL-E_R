<!DOCTYPE html>
<html>
  <head>
    <title>VALL-E R Demos</title>
    <link
      href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css"
      rel="stylesheet"
    />
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
    <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script>
    <script src="load_table.js" defer></script>
    <style>
      @import url(https://fonts.googleapis.com/css?family=Open+Sans);
      body {
        font-family: 'Open-Sans', sans-serif;
        font-weight: 300;
        background-color: #fff;
      }
      td {
        vertical-align: middle;
        text-align: justify;
        width: 0vw;
        min-width: 250px;
      }
      audio {
        width: 14vw;
        min-width: 100px;
      }
      .content {
        width: 69vw;
        padding: 25px 50px;
        margin: 25px auto;
        background-color: white;
        box-shadow: 0px 0px 10px #999;
        border-radius: 15px;
        font-family: "Google Sans";
      }
      .contentblock {
        width: 950px;
        margin: 0 auto;
        padding: 0;
        border-spacing: 25px 0;
      }
      .contentblock td {
        background-color: #fff;
        padding: 25px 50px;
        vertical-align: top;
        box-shadow: 0px 0px 10px #999;
        border-radius: 15px;
      }
      a, a:visited {
        color: #224b8d;
        font-weight: 300;
      }
      #authors {
        text-align: center;
        margin-bottom: 20px;
        font-size: 20px;
      }
      #conference {
        text-align: center;
        margin-bottom: 20px;
        font-style: italic;
      }
      #authors a {
        margin: 0 10px;
      }
      h1 {
        text-align: center;
        font-size: 35px;
        font-weight: 300;
      }
      h2 {
        font-size: 30px;
        font-weight: 300;
      }
      h3 {
        font-size: 25px;
        font-weight: 300;
      }
      h4 {
        font-size: 20px;
        font-weight: 300;
      }
      code {
        display: block;
        padding: 10px;
        margin: 10px 10px;
      }
      p {
        line-height: 25px;
        text-align: justify;
      }
      p code {
        display: inline;
        padding: 0;
        margin: 0;
      }
      #teasers {
        margin: 0 auto;
      }
      #teasers td {
        margin: 0 auto;
        text-align: center;
        padding: 5px;
      }
      #teasers img {
        width: 250px;
      }
      #results img {
        width: 133px;
      }
      #seeintodark {
        margin: 0 auto;
      }
      #sift {
        margin: 0 auto;
      }
      #sift img {
        width: 250px;
      }
      .downloadpaper {
        padding-left: 20px;
        float: right;
        text-align: center;
      }
      .downloadpaper a {
        font-weight: bold;
        text-align: center;
      }
      .teaser-img {
        width: 80%;
        display: block;
        margin-left: auto;
        margin-right: auto;
      }
      .teaser-gif {
        display: block;
        margin-left: auto;
        margin-right: auto;
      }
      .summary-img {
        width: 100%;
        display: block;
        margin-left: auto;
        margin-right: auto;
      }
      .video-iframe {
        width: 1000;
        height: 800;
        margin: auto;
        display: block;
      }
      .container {
        display: flex;
        align-items: center;
        justify-content: center
      }
      .image {
        flex-basis: 40%
      }
      .text {
        font-size: 20px;
        padding-left: 20px;
      }
      .center {
        margin-left: auto;
        margin-right: auto;
      }
      .boxshadow {
        border: 1px solid;
        padding: 10px;
        box-shadow: 2px 2px 5px #888888;
      }
      .spacertr {
        height: 8px;
      }
      .spacertd {
        width: 40px;
      }
    </style>
  </head>
  <body>
    <div class="content">
      <div class="text-center">
        <h1><strong>VALL-E R: Robust and Efficiency Zero-Shot Text-to-Speech via Monotonic Alignment</strong></h1>
        <h5></h5>
        <!-- <span style="font-size: 24px">Anonymous</span></p> -->
        <!-- <p class="lead fw-bold">
          |<a
            href=""
            class="btn border-white bg-white fw-bold"
            >paper</a
          >|
        </p> -->
      </div>
        <!-- <h4 style="text-align:center;">[<a href="#">Paper</a>] [<a href="pdfs/appendix.pdf">Appendix</a>]</h4> -->
        <h2 style="text-align:center;">Abstract</h2>
        <div style="text-align: justify;">
           <!-- With the help of discrete neural audio codecs, large language models (LLM) have increasingly been recognized as a promising methodology for zero-shot Text-to-Speech (TTS) synthesis. However, sampling based decoding strategies bring astonishing diversity to generation, but also pose robustness issues such as typos, omissions and repetition. In addition, the high sampling rate of audio also brings huge computational overhead to the inference process of autoregression. To alleviate these issues, we propose <b>VALL-E R</b>, which is a robust and efficiency zero-shot TTS system. Specifically, it introduces phoneme monotonic alignment strategy to enhance the connection between phonemes and acoustic sequence. And merge codec is adopt to downsample the discrete codes in shallow layer without affecting the speech quality. Benefit from these strategies, VALL-E R obtains controllablity over phonemes and demonstrates its strong robustness by approaching the WER of ground truth in experimental results. In addition, it requires fewer autoregressive steps during inference, resulting in over 60\% time savings in inference time. <br> -->

          With the help of discrete neural audio codecs, large language models (LLM) have increasingly been recognized as a promising methodology for zero-shot Text-to-Speech (TTS) synthesis. 
          However, sampling based decoding strategies bring astonishing diversity to generation, but also pose robustness issues such as typos, omissions and repetition. In addition, the high sampling rate of audio also brings huge computational overhead to the inference process of autoregression. 
          To address these issues, we propose <b>VALL-E R</b>, a robust and efficient zero-shot TTS system, building upon the foundation of VALL-E. Specifically, we introduce a phoneme monotonic alignment strategy to strengthen the connection between phonemes and acoustic sequence, ensuring a more precise alignment by constraining the acoustic tokens to match their associated phonemes.
          Furthermore, we employ a merge codec approach to downsample the discrete codes in shallow quantization layer, thereby accelerating the decoding speed while preserving the high quality of speech output. 
          Benefiting from these strategies, VALL-E R obtains controllablity over phonemes and demonstrates its strong robustness by approaching the WER of ground truth in experimental results. In addition, it requires fewer autoregressive steps during inference, resulting in over 60% time savings in inference time. <br>

           This page is for <b>research demonstration purposes only</b>.
        </div>
      </p>
    </div>
    <div class="content">
      <h2 id="model-overview" style="text-align: center;">Architecture Overview</h2>
      <body>
      <p style="text-align: center;">
        <img src="picture/valler_overview.png" style="width: 60vw; margin-left: 0vw;">
      </p>
        <div style="text-align: justify;">
          The overview of VALL-E R. It incorporate phoneme information (green) when predict audio codec (blue), which can enhance the connection between phoneme and audio to improve the robustness of decoder-only transformer TTS model.
        </div>
      </body>
    </div>


    <div class="content">
      <h2 style="text-align: center;">Samples of Merge Codec</h2>
      <div style="text-align: justify;">
      <body>
      <p style="text-align: center;">
        <img src="picture/merge_codec.png" style="width: 30vw; margin-left: 0vw;">
      </p>
        <div style="text-align: justify;">
          The architecture of proposed Merge Codec. Through the Merge module, the code in the first layer is downsampled twice, meaning that every two adjacent codes in the first layer are the same. The other layers remain unchanged.
        </div>
      </body>
      <HR>
      <b>Text</b>: Text transcription. <br>
      <b>Ground Truth</b>: Original speech waveform. <br>
      <b>Encodec</b>: Speech waveform reconstructed by Encodec. <br>
      <b>Merge Codec</b>: Speech waveform reconstructed by proposed Merge Codec. <br>
      <!-- Input is command text and source music, output is edited music -->
    </div>
    <div style="margin-top: 0vh; text-align: center;">
      <!-- <h3>Merge Codec</h3> -->
      <div class="table-responsive pt-3">
        <ul class="pagination justify-content-center">
          <li class="page-item active">
            <a id="codec-1" class="page-link" href="#">1</a>
          </li>
          <li class="page-item">
            <a id="codec-2" class="page-link" href="#">2</a>
          </li>
<!--           <li class="page-item">
            <a id="leying-3" class="page-link" href="#">leying page 3</a>
          </li> -->
        </ul>
        <table
          class="table pt-2"
          id="codec"
        >
          <thead>
            <tr>
              <th>Text</th>
              <th style="text-align: center;">Ground Truth</th>
              <th style="text-align: center">Merge Codec</th>
              <th style="text-align: center">Encodec</th>
              <!-- <th style="text-align: center">leying 4</th> -->
            </tr>
          </thead>
          <tbody></tbody>
        </table>
      </div>
    </div>
    </div>


    <div class="content">
      <h2 style="text-align: center;">Samples for Continue Voice Clone</h2>
      <div style="text-align: justify;">
      <b>Text</b>: Text transcription. <br>
      <b>Ground Truth</b>: Original speech waveform. <br>
      <b>Prompt</b>: The acoustic prompt. <br>
      <b>VALL-E</b>: Speech waveform generated by baseline VALL-E. <br>
      <b>VALL-E R</b>: Speech waveform generated by proposed VALL-E R. <br>
    </div>
      <div style="margin-top: 0vh; text-align: center;">
      <!-- <h3>continue</h3> -->
      <div class="table-responsive pt-3">
        <ul class="pagination justify-content-center">
          <li class="page-item active">
            <a id="continue-1" class="page-link" href="#">1</a>
          </li>
          <li class="page-item">
            <a id="continue-2" class="page-link" href="#">2</a>
          </li>
<!--           <li class="page-item">
            <a id="instr-operation-3" class="page-link" href="#">3</a> -->
          </li>
        </ul>
        <table
          class="table pt-2"
          id="continue"
        >
          <thead>
            <tr>
              <th>Text Prompt</th>
              <th style="text-align: center">Prompt</th>
              <th style="text-align: center">VALL-E R</th>
              <th style="text-align: center">VALL-E</th>
              <th style="text-align: center">Ground Truth</th>
              <!-- <th style="text-align: center">InstructME-acc</th> -->
<!--               <th style="text-align: center">InstructME-melody</th>
              <th style="text-align: center">AUDIT-acc</th>
              <th style="text-align: center">AUDIT-melody</th> -->
            </tr>
          </thead>
          <tbody></tbody>
        </table>
      </div>
      </div>

    </div> 



    <div class="content">
      <h2 style="text-align: center;">Samples for Cross-Sentence Voice Clone</h2>
      <div style="text-align: justify;">
      <b>Text</b>: Text transcription. <br>
      <!-- <b>Ground Truth</b>: Original speech waveform. <br> -->
      <b>Prompt</b>: The acoustic prompt. <br>
      <b>VALL-E</b>: Speech waveform generated by baseline VALL-E. <br>
      <b>VALL-E R</b>: Speech waveform generated by proposed VALL-E R. <br>
    </div>
      <div style="margin-top: 0vh; text-align: center;">
      <!-- <h3>cross</h3> -->
      <div class="table-responsive pt-3">
        <ul class="pagination justify-content-center">
          <li class="page-item active">
            <a id="cross-1" class="page-link" href="#">1</a>
          </li>
          <li class="page-item">
            <a id="cross-2" class="page-link" href="#">2</a>
          </li>
<!--           <li class="page-item">
            <a id="instr-operation-3" class="page-link" href="#">3</a> -->
          </li>
        </ul>
        <table
          class="table pt-2"
          id="cross"
        >
          <thead>
            <tr>
              <th>Text</th>
              <!-- <th style="text-align: center">Ground Truth</th> -->
              <th style="text-align: center">Prompt</th>
              <th style="text-align: center">VALL-E R</th>
              <th style="text-align: center">VALL-E</th>
              <!-- <th style="text-align: center">InstructME-acc</th> -->
<!--               <th style="text-align: center">InstructME-melody</th>
              <th style="text-align: center">AUDIT-acc</th>
              <th style="text-align: center">AUDIT-melody</th> -->
            </tr>
          </thead>
          <tbody></tbody>
        </table>
      </div>
      </div>
    </div> 



    <div class="content">
      <h2 style="text-align: center;">Samples for Prosody Control</h2>
      <div style="text-align: justify;">
      <b>Text</b>: Text transcription. <br>
      <!-- <b>Ground Truth</b>: Original speech waveform. <br> -->
      <b>Prompt</b>: The acoustic prompt provide timbre. <br>
      <b>Prosody Reference</b>: The acoustic prompt provide prosody. <br>
      <b>VALL-E R</b>: Speech waveform generated by proposed VALL-E R conditioned on timbre and prosody. <br>
      <!-- Input is command text and source music, output is edited music -->
    </div>
      
    <div style="margin-top: 0vh; text-align: center;">
      <!-- <h3>Merge Codec</h3> -->
      <div class="table-responsive pt-3">
        <ul class="pagination justify-content-center">
          <li class="page-item active">
            <a id="prosody-1" class="page-link" href="#">1</a>
          </li>
          <li class="page-item">
            <a id="prosody-2" class="page-link" href="#">2</a>
          </li>
        </ul>
        <table
          class="table pt-2"
          id="prosody"
        >
          <thead>
            <tr>
              <th>Text</th>
              <th style="text-align: center;">Prompt</th>
              <th style="text-align: center">Prosody Reference</th>
              <th style="text-align: center">VALL-E R</th>
              <!-- <th style="text-align: center">leying 4</th> -->
            </tr>
          </thead>
          <tbody></tbody>
        </table>
      </div>
    </div>
    </div>



    <div class="content">
      <h2 style="text-align: center;">Samples for Hard Samples</h2>
      <div style="text-align: justify;">
      <b>Text</b>: Text transcription. <br>
      <!-- <b>Ground Truth</b>: Original speech waveform. <br> -->
      <b>Prompt</b>: The acoustic prompt. <br>
      <b>VALL-E</b>: Speech waveform generated by baseline VALL-E. <br>
      <b>VALL-E R</b>: Speech waveform generated by proposed VALL-E R. <br>
    </div>
      <div style="margin-top: 0vh; text-align: center;">
      <!-- <h3>hard</h3> -->
      <div class="table-responsive pt-3">
        <ul class="pagination justify-content-center">
          <li class="page-item active">
            <a id="hard-1" class="page-link" href="#">1</a>
          </li>

          <li class="page-item">
            <a id="hard-2" class="page-link" href="#">2</a>
          </li>
<!--           <li class="page-item">
            <a id="instr-operation-3" class="page-link" href="#">3</a> -->
          </li>
        </ul>
        <table
          class="table pt-2"
          id="hard"
        >
          <thead>
            <tr>
              <th>Text</th>
              <th style="text-align: center">Prompt</th>
              <th style="text-align: center">VALL-E R</th>
              <!-- <th style="text-align: center">VALL-E</th> -->
              <th style="text-align: center">VALL-E</th>
              <!-- <th style="text-align: center">InstructME-acc</th> -->
<!--               <th style="text-align: center">InstructME-melody</th>
              <th style="text-align: center">AUDIT-acc</th>
              <th style="text-align: center">AUDIT-melody</th> -->
            </tr>
          </thead>
          <tbody></tbody>
        </table>
      </div>
      </div>
    </div> 
    </div>

    <div class="content">
      <h2 id="model-overview" style="text-align: center;">Ethics Statement</h2>
      <body>
<!--       <p style="text-align: center;">
        <img src="picture/valler_overview.png" style="width: 60vw; margin-left: 0vw;">
      </p> -->
        <div style="text-align: justify;">
          Since VALL-E R could synthesize speech that maintains speaker identity, it may carry potential risks in misuse of the model, such as spoofing voice identification or impersonating a specilic speaker. We conducted the experiments under the asumption that the user agree to be the taret speaker in speech synthesis. If the model is generalized to unseen speakers in the real world, it should include a protocol to ensure that the speaker approves the use of their voice and a synthesized speech detection model.
        </div>
      </body>
    </div>


    <p style="text-align: center;">
    <img src="https://badges.toozhao.com/badges/01HW75WW0HVJR8Q66FJKQ7ZE07/green.svg" />
    </p>
  </body>

</html>
